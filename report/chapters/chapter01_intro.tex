\chapter{Introduction}

A important thing when it comes to text mining is to create word embeddings. Those embeddings
are used for further analyses or more general as features in statistical models. GloVe is a 
technique to create word embeddings out of a given corpus. A very interesting thing is that
we want to learn from text without having labels. Hence, we have an unsupervised task. 


- word vectors (image ...)
- first terminology

In the following we want to discuss some important topics related to GloVe. After 
deriving the model with a more theoretical point of view in section \ref{ch:glove}. 
In section \ref{ch:eval} we also want to take a look at how to evaluating given word 
vectors which is quite interesting since we handle an unsupervised task. After that we 
take a short look at the data and common sources for text corpora in section \ref{ch:data}. \\

Then we know how to evaluate word vectors and have an idea about the data. With that 
knowledge we may ask how different methods to create word embeddings or different data 
sources influences the quality of the word vectors. This is discussed shortly in chapter
\ref{ch:real_wv}. After that we take a short look how we can use GloVe embeddings for
further text classification techniques followed from a small conclusion in section
\ref{ch:conclusion}.
