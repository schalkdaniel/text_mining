---
title: "GloVe: Global Vectors for Word Representation"
subtitle: "Text Mining Seminar"
author: "Daniel Schalk<span style='padding-left:620px;'>15. März 2017</span>"
output: 
  ioslides_presentation:
    widescreen: true
    css: ioslide.css
    self_contained: no
    includes:
      in_header: header.html
---

# Gliederung

# Wieso Wörter als Vektoren darstellen?

# GloVe Modell

## Theorie

- Wo startet man
- Wo will man hin
- Annahmen, Restriktionen etc. 
- Welcher Algorithmus wird beim fitten verwendet?

We perform GloVe fitting using AdaGrad - stochastic gradient descend with 
per-feature adaptive learning rate. Also, fitting is done in fully parallel 
and asynchronous manner ( see Hogwild! paper ), so it can benefit from machines 
with multiple cores. In my tests I achieved almost 8x speedup on 8 core machine 
on the discribed above wikipedia dataset.

- Welche hyperparameter werden empfohlen (steht in paper)

## Evaluierung

- "Cosine Similarity" erklären
- Was kann man noch machen?

# `R` Implementierung `text2vec`

## `text2vec`

- Implementierung `R6`, `Rcpp` (`C++`), `RcppParallel` (moderne + sauber)
- Wichtigste Befehle erklären
- Leider nicht sehr gut gemaintained

# Daten und Usecase

## Daten

- Man brauch fucking viele Wörter (riesen Corpus, Wikipedia). Mega Hussle.

- Man könnte andere sources nehmen, z. B. Statistik Sachbücher um Statistik
  Vokabular zu lernen
  
- Was zum fitten sagen, welche hyperparameter (evtl. schon in Theorie und
  referenzieren)
  
- Deutsch nicht so geil, zu viele Wörter die extrem selten vorkommen.

- Stopwords from http://snowballstem.org

## Usecase

- Ähnlichkeiten: Leicht anfangen, d. h. einfach in euklidischer Norm 
  illustrieren mit Bildern
  
- Ähnlichkeiten: women to queen wie men to ???

- `d3` Visualisierungen raus ballern (clustern, ...)

# Ausblick

- Clustern von Artikeln nach Wörtern


# Ideas

## Todos Visualization

- Shiny App, die Dokumente l?dt und Darauf glove anwendet. Die Parameter sollen
  verstellbar sein, Gr??eres Fenster etc. Die App speichert dann eine YAML Datei
  ab, in welcher die Wortzusammenhänge drin sind.
  
- Nachdem man den Text ausgewertet hat sollen die W?rter analog zu
  [diesem Beispiel](https://bl.ocks.org/mbostock/1044242) visualisiert werden.
  Dabei sollen ?nnliche W?rter zusammen geclustert sein nach GloVe oder SVD oder
  sonst was. Geht man dann auf ein Wort sollen die "most frequent words" in dem
  Kontext zu dem Wort auf dem die Maus ist angezeigt werden.

# <i class="fa fa-sitemap"></i> Class System

## <i class="fa fa-sitemap"></i> 2 Approaches

<div class="cols">
  <div class="box1">
  <center>
  <font size="7">C++</font>
  </center>
  </div>
  <div class="box2">
  <p>Solid <code>C++</code> base with </p>
  <ul>
  <li> Own class system for "frequently used" base learner </li>
  <li> Give the opportunity to extend the the functionality with own 
       <code>C++</code> functions </li>
  </ul>
  </div>
</div>

<br>

<div class="cols">
  <div class="box1">
  <center>
  <font size="7">R</font>
  </center>
  </div>
  <div class="box2">
  <p><code>R</code> API and wrapper around the core <code>C++</code> functionality:</p>
  <ul>
  <li> Basically the same as in <code>C++</code> but much more easier to extend 
       with own base learner and loss/gradient </li>
  <li> Functions to summarize, visualize the results and to refit the
       model etc.</li>
  </ul>
  </div>
</div>
